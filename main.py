import os
import uuid
from flask import Flask, request
from linebot.v3.messaging import MessagingApi, Configuration, ApiClient, ReplyMessageRequest, TextMessage
from linebot.v3.webhook import WebhookParser
from linebot.v3.webhooks import MessageEvent, TextMessageContent
from openai import OpenAI
from dotenv import load_dotenv
from pinecone import Pinecone

# è¨˜æ†¶å°è©± & äººå·¥å®¢æœæ¨¡å¼
from collections import defaultdict, deque
user_memory = defaultdict(lambda: deque(maxlen=10))
manual_mode = set()  # å­˜æ”¾é€²å…¥äººå·¥å®¢æœæ¨¡å¼çš„ user_id

load_dotenv()
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
index = pc.Index(os.getenv("PINECONE_INDEX"))
configuration = Configuration(access_token=os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
parser = WebhookParser(os.getenv("LINE_CHANNEL_SECRET"))
app = Flask(__name__)

@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("x-line-signature")
    body = request.get_data(as_text=True)

    try:
        events = parser.parse(body, signature)
    except:
        return "Invalid signature", 400

    with ApiClient(configuration) as api_client:
        line_bot_api = MessagingApi(api_client)

        for event in events:
            if isinstance(event, MessageEvent) and isinstance(event.message, TextMessageContent):
                user_id = event.source.user_id
                query = event.message.text.strip()

                # âœ… å°è©±è¨˜æ†¶ï¼ˆä¸è«–æ˜¯å¦äººå·¥ï¼‰
                user_memory[user_id].append({"role": "user", "content": query})

                # âœ… åˆ‡æ›äººå·¥å®¢æœå•Ÿç”¨
                if query == "äººå·¥å®¢æœæ‚¨å¥½":
                    manual_mode.add(user_id)
                    print(f"[äººå·¥æ¨¡å¼ ON] {user_id}")
                    return "OK", 200

                # âœ… çµæŸäººå·¥å®¢æœ
                if query == "äººå·¥å®¢æœçµæŸ":
                    manual_mode.discard(user_id)
                    print(f"[äººå·¥æ¨¡å¼ OFF] {user_id}")
                    return "OK", 200

                # âœ… å¦‚æœæ˜¯äººå·¥å®¢æœæ¨¡å¼ï¼Œä¸å›è¦†ä½†è¨˜æ†¶
                if user_id in manual_mode:
                    print(f"[éœé»˜ä¸­] {user_id} ç‚ºäººå·¥å®¢æœä¸­ï¼Œè·³é GPT å›è¦†")
                    return "OK", 200

                # âœ… æŸ¥è©¢ Pinecone
                vector = embed_text(query)
                res = index.query(vector=vector, top_k=5, include_metadata=True)
                matches = [m for m in res["matches"] if m["score"] >= 0.2]

                if not matches:
                    fallback = "äºéˆºæ™ºèƒ½å®¢æœæ‚¨å¥½ï¼šæ„Ÿè¬æ‚¨çš„è©¢å•ï¼Œç›®å‰æ‚¨çš„å•é¡Œéœ€è¦å°ˆäººå›è¦†æ‚¨ï¼Œè«‹ç¨å¾Œé¦¬ä¸Šæœ‰äººç‚ºæ‚¨æœå‹™ï¼ğŸ˜„"
                    user_memory[user_id].append({"role": "assistant", "content": fallback})
                    line_bot_api.reply_message(ReplyMessageRequest(
                        reply_token=event.reply_token,
                        messages=[TextMessage(text=fallback)]
                    ))
                    return "OK", 200

                context = "\n".join([m["metadata"]["text"] for m in matches])

                memory_messages = list(user_memory[user_id])
                memory_messages.append({"role": "user", "content": query})

                system_prompt = {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯äºéˆºæ±½è»Šçš„50å¹´è³‡æ·±å®¢æœå°ˆå“¡ï¼Œæ“…é•·è§£æ±ºå•é¡Œä¸”æ“…é•·æ€è€ƒæ‹†è§£å•é¡Œï¼Œ"
                        "è«‹å…ˆé€éåƒè€ƒè³‡æ–™åˆ¤æ–·ä¸¦è§£æå•é¡Œé»ï¼Œåªè©¢å•åƒè€ƒè³‡æ–™éœ€è¦çš„å•é¡Œï¼Œ"
                        "ä¸è¦å•ä¸ç›¸é—œåƒè€ƒè³‡æ–™çš„å•é¡Œï¼Œå¦‚æœè©¢å•å…§å®¹ä¸åœ¨åƒè€ƒè³‡æ–™å…§ï¼Œè«‹å…ˆåˆ¤æ–·é€™å¥è©±æ˜¯ä»€éº¼é¡å‹çš„å•é¡Œï¼Œ"
                        "ç„¶å¾Œé‡å°åƒè€ƒè³‡æ–™å…§çš„è³‡æ–™åšåå•å•é¡Œï¼Œæœ€å¾Œå•åˆ°éœ€è¦çš„ç­”æ¡ˆï¼Œè«‹ç”¨æœ€ç©æ¥µèˆ‡å……æ»¿æº«åº¦çš„æ–¹å¼å›ç­”ï¼Œ"
                        "è‹¥åƒè€ƒè³‡æ–™èˆ‡å•é¡Œç„¡é—œï¼Œæ¯”å¦‚ä»–æ˜¯ä¾†èŠå¤©çš„ï¼Œè«‹å›è¦†ç½é ­è¨Šæ¯ï¼š\"æ„Ÿè¬æ‚¨çš„è©¢å•ï¼Œè«‹è©¢å•äºéˆºæ±½è»Šç›¸é—œå•é¡Œï¼Œæˆ‘å€‘å¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ï¼ğŸ˜„\""
                    )
                }
                user_prompt = {
                    "role": "user",
                    "content": f"åƒè€ƒè³‡æ–™ï¼š{context}\n\nå•é¡Œï¼š{query}"
                }
                chat_completion = openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[system_prompt] + memory_messages + [user_prompt]
                )
                answer = chat_completion.choices[0].message.content.strip()
                if not answer.startswith("äºéˆºæ™ºèƒ½å®¢æœæ‚¨å¥½ï¼š"):
                    answer = "äºéˆºæ™ºèƒ½å®¢æœæ‚¨å¥½ï¼š" + answer

                user_memory[user_id].append({"role": "assistant", "content": answer})
                line_bot_api.reply_message(ReplyMessageRequest(
                    reply_token=event.reply_token,
                    messages=[TextMessage(text=answer)]
                ))
    return "OK", 200

@app.route("/")
def home():
    return "LINE GPT Bot Ready"

@app.route("/upload", methods=["POST"])
def upload_text():
    data = request.get_json()
    text = data.get("text", "").strip()

    if not text:
        return {"error": "Missing text"}, 400

    embedding = embed_text(text)
    id = "web-" + str(uuid.uuid4())[:8]

    index.upsert([
        {
            "id": id,
            "values": embedding,
            "metadata": {"text": text}
        }
    ])
    return {"message": "âœ… ä¸Šå‚³æˆåŠŸ", "id": id}

def embed_text(text):
    embedding = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=[text]
    )
    return embedding.data[0].embedding

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000)
